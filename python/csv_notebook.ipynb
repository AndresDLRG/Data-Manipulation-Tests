{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a639cd",
   "metadata": {},
   "source": [
    "# Data Processing Libraries Comparison\n",
    "\n",
    "This notebook compares different data processing libraries: Pandas, Polars, DuckDB, and PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f8c2d",
   "metadata": {},
   "source": [
    "## Configuration and Imports\n",
    "\n",
    "First, we'll set up our environment and import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03f21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path\n",
    "DATA_FILE = '../files/sample_ads_data.csv'\n",
    "\n",
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import duckdb\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Performance measurement imports\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Initialize PySpark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Helper function for performance measurement\n",
    "def measure_performance(func):\n",
    "    \"\"\"Measure execution time and memory usage of a function\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_memory = process.memory_info().rss / 1024 / 1024  # Memory in MB\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = func()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_memory = process.memory_info().rss / 1024 / 1024\n",
    "    \n",
    "    return {\n",
    "        'execution_time': end_time - start_time,\n",
    "        'memory_used': end_memory - start_memory,\n",
    "        'result': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe378c27",
   "metadata": {},
   "source": [
    "# Performance Comparisons\n",
    "\n",
    "Let's compare the performance of different operations across all four libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d5510",
   "metadata": {},
   "source": [
    "## 1. Data Loading Performance\n",
    "Compare how fast each library loads the CSV file and how much memory it uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455d618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Loading Time (s)</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas</td>\n",
       "      <td>20.380</td>\n",
       "      <td>1642.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polars</td>\n",
       "      <td>2.119</td>\n",
       "      <td>1259.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>16.334</td>\n",
       "      <td>-2856.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>4.345</td>\n",
       "      <td>1.699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library  Loading Time (s)  Memory Used (MB)\n",
       "0   pandas            20.380          1642.121\n",
       "1   polars             2.119          1259.648\n",
       "2   duckdb            16.334         -2856.938\n",
       "3  pyspark             4.345             1.699"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data loading for each library\n",
    "results = {}\n",
    "\n",
    "# Pandas\n",
    "results['pandas'] = measure_performance(\n",
    "    lambda: pd.read_csv(DATA_FILE)\n",
    ")\n",
    "df = results['pandas']['result']\n",
    "\n",
    "# Polars (force eager evaluation)\n",
    "results['polars'] = measure_performance(\n",
    "    lambda: pl.read_csv(DATA_FILE)\n",
    ")\n",
    "df_pl = results['polars']['result']\n",
    "\n",
    "# DuckDB (already eager, but ensure result is materialized)\n",
    "results['duckdb'] = measure_performance(\n",
    "    lambda: duckdb.query(f\"SELECT * FROM read_csv('{DATA_FILE}', quote='\\\"')\").df()\n",
    ")\n",
    "df_duck = results['duckdb']['result']\n",
    "\n",
    "# PySpark (convert to pandas to force full load in memory)\n",
    "results['pyspark'] = measure_performance(\n",
    "    lambda: spark.read.csv(DATA_FILE, header=True, inferSchema=True)\n",
    ")\n",
    "df_spark = results['pyspark']['result']\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame({\n",
    "    'Library': list(results.keys()),\n",
    "    'Loading Time (s)': [r['execution_time'] for r in results.values()],\n",
    "    'Memory Used (MB)': [r['memory_used'] for r in results.values()]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009496e",
   "metadata": {},
   "source": [
    "## 2. Filtering Performance\n",
    "Compare how fast each library can filter data based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1f27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas count: 249602\n",
      "Polars count: 249602\n",
      "DuckDB count: 249602\n",
      "PySpark count: 249602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Filtering Time (s)</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas</td>\n",
       "      <td>4.506</td>\n",
       "      <td>1621.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polars</td>\n",
       "      <td>0.150</td>\n",
       "      <td>43.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>1.138</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library  Filtering Time (s)  Memory Used (MB)\n",
       "0   pandas               4.506          1621.137\n",
       "1   polars               0.150            43.359\n",
       "2   duckdb               0.025             0.559\n",
       "3  pyspark               1.138             0.113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test filtering performance\n",
    "filter_results = {}\n",
    "\n",
    "# Pandas\n",
    "filter_results['pandas'] = measure_performance(\n",
    "    lambda: df[df['account_id'] == 'ACC0001'].shape[0]\n",
    ")\n",
    "# Polars\n",
    "filter_results['polars'] = measure_performance(\n",
    "    lambda: df_pl.filter(pl.col('account_id') == 'ACC0001').shape[0]\n",
    ")\n",
    "\n",
    "# DuckDB\n",
    "filter_results['duckdb'] = measure_performance(\n",
    "    lambda: duckdb.query(\"SELECT count(*) FROM df_duck WHERE account_id = 'ACC0001'\").df().iloc[0, 0]\n",
    ")\n",
    "\n",
    "# PySpark\n",
    "filter_results['pyspark'] = measure_performance(\n",
    "    lambda: df_spark.filter(df_spark['account_id'] == 'ACC0001').count()\n",
    ")\n",
    "\n",
    "# Print counts for each library\n",
    "print(\"Pandas count:\", filter_results['pandas']['result'])\n",
    "print(\"Polars count:\", filter_results['polars']['result'])\n",
    "print(\"DuckDB count:\", filter_results['duckdb']['result'])\n",
    "print(\"PySpark count:\", filter_results['pyspark']['result'])\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame({\n",
    "    'Library': list(filter_results.keys()),\n",
    "    'Filtering Time (s)': [r['execution_time'] for r in filter_results.values()],\n",
    "    'Memory Used (MB)': [r['memory_used'] for r in filter_results.values()]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81953b93",
   "metadata": {},
   "source": [
    "## 3. GroupBy and Aggregation Performance\n",
    "Compare how fast each library can perform groupby operations and aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6432b38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>GroupBy Time (s)</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2.408</td>\n",
       "      <td>78.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polars</td>\n",
       "      <td>1.475</td>\n",
       "      <td>2235.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>0.067</td>\n",
       "      <td>2.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>5.102</td>\n",
       "      <td>1.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library  GroupBy Time (s)  Memory Used (MB)\n",
       "0   pandas             2.408            78.668\n",
       "1   polars             1.475          2235.391\n",
       "2   duckdb             0.067             2.453\n",
       "3  pyspark             5.102             1.637"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test groupby and aggregation performance\n",
    "groupby_results = {}\n",
    "\n",
    "# Pandas\n",
    "groupby_results['pandas'] = measure_performance(\n",
    "    lambda: df.groupby('account_id')['campaign_id'].count()\n",
    ")\n",
    "\n",
    "# Polars\n",
    "groupby_results['polars'] = measure_performance(\n",
    "    lambda: df_pl.group_by('account_id').agg(pl.col('campaign_id').count())\n",
    ")\n",
    "\n",
    "# DuckDB\n",
    "groupby_results['duckdb'] = measure_performance(\n",
    "    lambda: duckdb.query(\"SELECT account_id, COUNT(campaign_id) as count FROM df_duck GROUP BY account_id\")\n",
    ")\n",
    "\n",
    "# PySpark\n",
    "groupby_results['pyspark'] = measure_performance(\n",
    "    lambda: df_spark.groupBy('account_id').count().toPandas()\n",
    ")\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame({\n",
    "    'Library': list(groupby_results.keys()),\n",
    "    'GroupBy Time (s)': [r['execution_time'] for r in groupby_results.values()],\n",
    "    'Memory Used (MB)': [r['memory_used'] for r in groupby_results.values()]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d591937",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 4. Add new column Performance\n",
    "Compare how fast each library can add a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cc808",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>AddCol Time (s)</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas</td>\n",
       "      <td>0.012</td>\n",
       "      <td>34.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polars</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library  AddCol Time (s)  Memory Used (MB)\n",
       "0   pandas            0.012             34.43\n",
       "1   polars            0.004              3.43\n",
       "2   duckdb            0.005              0.02\n",
       "3  pyspark            0.007              0.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare performance of adding a new column with default value\n",
    "addcol_results = {}\n",
    "\n",
    "# Pandas\n",
    "addcol_results['pandas'] = measure_performance(\n",
    "    lambda: df.assign(NewCol='default')\n",
    ")\n",
    "\n",
    "# Polars\n",
    "addcol_results['polars'] = measure_performance(\n",
    "    lambda: df_pl.with_columns([pl.lit('default').alias('NewCol')])\n",
    ")\n",
    "\n",
    "# DuckDB\n",
    "addcol_results['duckdb'] = measure_performance(\n",
    "    lambda: duckdb.query(\"SELECT *, 'default' AS NewCol FROM df_duck\")\n",
    ")\n",
    "\n",
    "# PySpark\n",
    "addcol_results['pyspark'] = measure_performance(\n",
    "    lambda: df_spark.withColumn('NewCol', F.lit('default'))\n",
    ")\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame({\n",
    "    'Library': list(addcol_results.keys()),\n",
    "    'AddCol Time (s)': [r['execution_time'] for r in addcol_results.values()],\n",
    "    'Memory Used (MB)': [r['memory_used'] for r in addcol_results.values()]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbaaafe",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 5. Hash Operation Performance\n",
    "Compare how fast each library can compute a hash of the 'VIN' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a944ec7b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Hash Time (s)</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas</td>\n",
       "      <td>3.917</td>\n",
       "      <td>283.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polars</td>\n",
       "      <td>4.371</td>\n",
       "      <td>461.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>0.059</td>\n",
       "      <td>81.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library  Hash Time (s)  Memory Used (MB)\n",
       "0   pandas          3.917           283.676\n",
       "1   polars          4.371           461.555\n",
       "2   duckdb          0.059            81.250\n",
       "3  pyspark          0.009             0.000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare performance of hashing the 'County' column\n",
    "hash_results = {}\n",
    "\n",
    "# Pandas\n",
    "import hashlib\n",
    "hash_results['pandas'] = measure_performance(\n",
    "    lambda: df['date'].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n",
    ")\n",
    "\n",
    "# Polars\n",
    "hash_results['polars'] = measure_performance(\n",
    "    lambda: df_pl.with_columns([\n",
    "        df_pl.get_column('date').map_elements(lambda x: hashlib.sha256(str(x).encode()).hexdigest(), return_dtype=pl.String).alias('date_hash')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# DuckDB\n",
    "hash_results['duckdb'] = measure_performance(\n",
    "    lambda: duckdb.query(\"SELECT *, sha256(CAST(date as VARCHAR)) AS date_hash FROM df_duck\")\n",
    ")\n",
    "\n",
    "# PySpark\n",
    "hash_results['pyspark'] = measure_performance(\n",
    "    lambda: df_spark.withColumn('date_hash', F.sha2(F.col('date').cast('string'), 256))\n",
    ")\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame({\n",
    "    'Library': list(hash_results.keys()),\n",
    "    'Hash Time (s)': [r['execution_time'] for r in hash_results.values()],\n",
    "    'Memory Used (MB)': [r['memory_used'] for r in hash_results.values()]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b646d2",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "After running these comparisons, you can evaluate each library based on:\n",
    "\n",
    "1. **Performance**\n",
    "   - Loading speed\n",
    "   - Memory usage\n",
    "   - Operation speed (filtering, groupby)\n",
    "\n",
    "2. **Syntax**\n",
    "   - Code readability\n",
    "   - API consistency\n",
    "   - Learning curve\n",
    "\n",
    "3. **Use Cases**\n",
    "   - Pandas: Best for small to medium datasets, interactive analysis\n",
    "   - Polars: Great for large datasets on a single machine\n",
    "   - DuckDB: Excellent for SQL users and complex queries\n",
    "   - PySpark: Ideal for distributed processing and very large datasets\n",
    "\n",
    "Choose the library that best fits your specific needs based on:\n",
    "- Dataset size\n",
    "- Performance requirements\n",
    "- Team expertise\n",
    "- Integration needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
